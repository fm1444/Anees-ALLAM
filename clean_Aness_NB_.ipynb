{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SohhtnE-EPko"
      },
      "source": [
        "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
        "# Prompt Notebook with Chat - Prompt Lab Notebook v1.1.0\n",
        "This notebook contains steps and code to demonstrate inferencing of prompts\n",
        "generated in Prompt Lab in watsonx.ai with a chat format. It introduces Python API commands\n",
        "for authentication using API key and prompt inferencing using WML API.\n",
        "\n",
        "**Note:** Notebook code generated using Prompt Lab will execute successfully.\n",
        "If code is modified or reordered, there is no guarantee it will successfully execute.\n",
        "For details, see: <a href=\"/docs/content/wsj/analyze-data/fm-prompt-save.html?context=wx\" target=\"_blank\">Saving your work in Prompt Lab as a notebook.</a>\n",
        "\n",
        "Some familiarity with Python is helpful. This notebook uses Python 3.10.\n",
        "\n",
        "## Notebook goals\n",
        "The learning goals of this notebook are:\n",
        "\n",
        "* Defining a Python function for obtaining credentials from the IBM Cloud personal API key\n",
        "* Defining parameters of the Model object\n",
        "* Using the Model object to generate response using the defined model id, parameters and the prompt input\n",
        "\n",
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udKZjsAxEPkv"
      },
      "source": [
        "## watsonx API connection\n",
        "This cell defines the credentials required to work with watsonx API for Foundation\n",
        "Model inferencing.\n",
        "\n",
        "**Action:** Provide the IBM Cloud personal API key. For details, see\n",
        "<a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\">documentation</a>.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2P3lx6hJElMc",
        "outputId": "3f2fbe88-13cd-4fd7-d42c-9fc621e928a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ibm-watsonx-ai in /usr/local/lib/python3.10/dist-packages (1.1.22)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ibm-watsonx-ai) (2.32.2)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from ibm-watsonx-ai) (0.27.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from ibm-watsonx-ai) (2.2.3)\n",
            "Requirement already satisfied: pandas<2.2.0,>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from ibm-watsonx-ai) (2.1.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from ibm-watsonx-ai) (2024.8.30)\n",
            "Requirement already satisfied: lomond in /usr/local/lib/python3.10/dist-packages (from ibm-watsonx-ai) (0.3.3)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from ibm-watsonx-ai) (0.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ibm-watsonx-ai) (24.1)\n",
            "Requirement already satisfied: ibm-cos-sdk<2.14.0,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from ibm-watsonx-ai) (2.13.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from ibm-watsonx-ai) (8.5.0)\n",
            "Requirement already satisfied: ibm-cos-sdk-core==2.13.6 in /usr/local/lib/python3.10/dist-packages (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watsonx-ai) (2.13.6)\n",
            "Requirement already satisfied: ibm-cos-sdk-s3transfer==2.13.6 in /usr/local/lib/python3.10/dist-packages (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watsonx-ai) (2.13.6)\n",
            "Requirement already satisfied: jmespath<=1.0.1,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watsonx-ai) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from ibm-cos-sdk-core==2.13.6->ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watsonx-ai) (2.9.0.post0)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0,>=0.24.2->ibm-watsonx-ai) (1.26.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0,>=0.24.2->ibm-watsonx-ai) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0,>=0.24.2->ibm-watsonx-ai) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ibm-watsonx-ai) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ibm-watsonx-ai) (3.10)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->ibm-watsonx-ai) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->ibm-watsonx-ai) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->ibm-watsonx-ai) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->ibm-watsonx-ai) (0.14.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->ibm-watsonx-ai) (3.20.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from lomond->ibm-watsonx-ai) (1.16.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->ibm-watsonx-ai) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install ibm-watsonx-ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwIEs6VXEPk5",
        "outputId": "2b3a3552-e2a9-470b-e79f-539c3f82c716"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVm_kbG8EoWm",
        "outputId": "c83bf6cc-ec90-4b43-936d-7a689b8895b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting elevenlabs\n",
            "  Downloading elevenlabs-1.12.1-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from elevenlabs) (0.27.2)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from elevenlabs) (2.9.2)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.10/dist-packages (from elevenlabs) (2.23.4)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from elevenlabs) (2.32.2)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from elevenlabs) (4.12.2)\n",
            "Collecting websockets>=11.0 (from elevenlabs)\n",
            "  Downloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->elevenlabs) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->elevenlabs) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->elevenlabs) (1.0.6)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->elevenlabs) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->elevenlabs) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.21.2->elevenlabs) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->elevenlabs) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->elevenlabs) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->elevenlabs) (2.2.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->elevenlabs) (1.2.2)\n",
            "Downloading elevenlabs-1.12.1-py3-none-any.whl (150 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.5/150.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (164 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.1/164.1 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: websockets, elevenlabs\n",
            "Successfully installed elevenlabs-1.12.1 websockets-13.1\n"
          ]
        }
      ],
      "source": [
        "pip install elevenlabs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4n-fVidKEPk5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26f4d409-922e-41f5-fdcf-2989049be23d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.44.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.5.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.24.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (10.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.19.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fXFZTVbWEPk3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e100a6fd-2dd2-4f4f-deff-55cd0f7811c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-0.5.18-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.9.2)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.115.4-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.26.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.7.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.20.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.16.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.49b1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.16.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.19.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.6)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.64.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.12.5)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.10)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.27.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (13.9.3)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (24.1)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.2)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.41.2-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.0.6)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.2)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (75.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.65.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.28.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.28.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.28.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.28.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.49b1-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting opentelemetry-instrumentation==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.49b1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.49b1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-util-http==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.49b1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.49b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.49b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.28.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.23.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.24.7)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (13.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.20.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-0.5.18-py3-none-any.whl (615 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.5/615.5 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl (273 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading fastapi-0.115.4-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.28.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.28.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.28.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.49b1-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.49b1-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.49b1-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.49b1-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.2/159.2 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.28.1-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_util_http-0.49b1-py3-none-any.whl (6.9 kB)\n",
            "Downloading opentelemetry_sdk-1.28.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.7.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading starlette-0.41.2-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (425 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=a09a22080c7f0cbf4a47291bf74dca4c2b582761821a43e3198819b989d90238\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, durationpy, uvloop, uvicorn, python-dotenv, pyproject_hooks, protobuf, overrides, opentelemetry-util-http, mmh3, humanfriendly, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-proto, opentelemetry-api, coloredlogs, build, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, onnxruntime, kubernetes, fastapi, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.16.0\n",
            "    Uninstalling opentelemetry-api-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.16.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.37b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.37b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.37b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.16.0\n",
            "    Uninstalling opentelemetry-sdk-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-cloud-datastore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.3 which is incompatible.\n",
            "google-cloud-firestore 2.16.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.3 which is incompatible.\n",
            "tensorboard 2.17.0 requires protobuf!=4.24.0,<5.0.0,>=3.19.6, but you have protobuf 5.28.3 which is incompatible.\n",
            "tensorflow 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 5.28.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.0 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.5.18 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.4 httptools-0.6.4 humanfriendly-10.0 kubernetes-31.0.0 mmh3-5.0.1 monotonic-1.6 onnxruntime-1.20.0 opentelemetry-api-1.28.1 opentelemetry-exporter-otlp-proto-common-1.28.1 opentelemetry-exporter-otlp-proto-grpc-1.28.1 opentelemetry-instrumentation-0.49b1 opentelemetry-instrumentation-asgi-0.49b1 opentelemetry-instrumentation-fastapi-0.49b1 opentelemetry-proto-1.28.1 opentelemetry-sdk-1.28.1 opentelemetry-semantic-conventions-0.49b1 opentelemetry-util-http-0.49b1 overrides-7.7.0 posthog-3.7.0 protobuf-5.28.3 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.0.1 starlette-0.41.2 uvicorn-0.32.0 uvloop-0.21.0 watchfiles-0.24.0\n"
          ]
        }
      ],
      "source": [
        "pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-rYzFlMVD1Tf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66d09e1f-0ee3-4f27-9aa6-2a3aeb595c01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.12 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.13)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.137)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.10)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain) (3.0.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7_j6NUP3IWNF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62c6a665-8cf5-4728-fa89-01215957b987"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/800.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.5.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.6)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.5.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting triton>=2.0.0 (from openai-whisper)\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.32.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803321 sha256=efa35df2f8346325413d7d974e4d814f28d97fe6d84dd8a00cbd04b8e45e2acc\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/4a/1f/d1c4bf3b9133c8168fe617ed979cab7b14fe381d059ffb9d83\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: triton, tiktoken, openai-whisper\n",
            "Successfully installed openai-whisper-20240930 tiktoken-0.8.0 triton-3.1.0\n"
          ]
        }
      ],
      "source": [
        "pip install openai-whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OJ4Xh3vqTiVd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2794b48-8268-4a0d-cbac-f9928d45ee9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ],
      "source": [
        "pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "AUblpDgvHaUc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d0104f2-e1a9-43fd-98f5-18aa44928386"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using existing collection for story\n",
            "Loading /content/qesas.pdf for story\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-0\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-0\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-1\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-1\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-2\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-2\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-3\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-3\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-4\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-4\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-5\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-5\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-6\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-6\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-7\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-7\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-8\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-8\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-9\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-9\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-10\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-10\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-11\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-11\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-12\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-12\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-13\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-13\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-14\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-14\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-15\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-15\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-16\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-16\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-17\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-17\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-18\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-18\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-19\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-19\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-20\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-20\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-21\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-21\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-22\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-22\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-23\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-23\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-24\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-24\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-25\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-25\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-26\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-26\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-27\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-27\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-28\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-28\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-29\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-29\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-30\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-30\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-31\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-31\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-32\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-32\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-33\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-33\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-34\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-34\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-35\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-35\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-36\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-36\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-37\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-37\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-38\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-38\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-39\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-39\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-40\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-40\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-41\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-41\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-42\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-42\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-43\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-43\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-44\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-44\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-45\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-45\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-46\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-46\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-47\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-47\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-48\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-48\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-49\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-49\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-50\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-50\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-51\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-51\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-52\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-52\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-53\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-53\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-54\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-54\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-55\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-55\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-56\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-56\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-57\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-57\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-58\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-58\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-59\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-59\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-60\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-60\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-61\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-61\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-62\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-62\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-63\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-63\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-64\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-64\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-65\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-65\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-66\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-66\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-67\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-67\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-68\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-68\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-69\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-69\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-70\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-70\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-71\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-71\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-72\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-72\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-73\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-73\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-74\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-74\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-75\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-75\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-76\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-76\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-77\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-77\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-78\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-78\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-79\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-79\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-80\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-80\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-81\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-81\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-82\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-82\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-83\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-83\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-84\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-84\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-85\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-85\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-86\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-86\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-87\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-87\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-88\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-88\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-89\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-89\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-90\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-90\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-91\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-91\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-92\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-92\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-93\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-93\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-94\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-94\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-95\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-95\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-96\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-96\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-97\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-97\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-98\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-98\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-99\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-99\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-100\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-100\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-101\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-101\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-102\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-102\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-103\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-103\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-104\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-104\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-105\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-105\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-106\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-106\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-107\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-107\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-108\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-108\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-109\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-109\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-110\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-110\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-111\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-111\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-112\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-112\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-113\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-113\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-114\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-114\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-115\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-115\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-116\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-116\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-117\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-117\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-118\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-118\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-119\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-119\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-120\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-120\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-121\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-121\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-122\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-122\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-123\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-123\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-124\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-124\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-125\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-125\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-126\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-126\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-127\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-127\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-128\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-128\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-129\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-129\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-130\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-130\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-131\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-131\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-132\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-132\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-133\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-133\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-134\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-134\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-135\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-135\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-136\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-136\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-137\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-137\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-138\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-138\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-139\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-139\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-140\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-140\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-141\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-141\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-142\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-142\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-143\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-143\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-144\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-144\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-145\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-145\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-146\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-146\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-147\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-147\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-148\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-148\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-149\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-149\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-150\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-150\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-151\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-151\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-152\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-152\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-153\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-153\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-154\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-154\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-155\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-155\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-156\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-156\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-157\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-157\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-158\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-158\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-159\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-159\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-160\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-160\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-161\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-161\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-162\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-162\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-163\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-163\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-164\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-164\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-165\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-165\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-166\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-166\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-167\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-167\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-168\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-168\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-169\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-169\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-170\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-170\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-171\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-171\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-172\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-172\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-173\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-173\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-174\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-174\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-175\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-175\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-176\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-176\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-177\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-177\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-178\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-178\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-179\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-179\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-180\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-180\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-181\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-181\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-182\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-182\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-183\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-183\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-184\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-184\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-185\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-185\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-186\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-186\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-187\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-187\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-188\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-188\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-189\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-189\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-190\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-190\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-191\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-191\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-192\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-192\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-193\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-193\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-194\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-194\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-195\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-195\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-196\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-196\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-197\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-197\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-198\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-198\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-199\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-199\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-200\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-200\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-201\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-201\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-202\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-202\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-203\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-203\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-204\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-204\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-205\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-205\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-206\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-206\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-207\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-207\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-208\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-208\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-209\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-209\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-210\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-210\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-211\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-211\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-212\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-212\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-213\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-213\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-214\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-214\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-215\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-215\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-216\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-216\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: /content/qesas.pdf-chunk-217\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: /content/qesas.pdf-chunk-217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indexed document /content/qesas.pdf in 218 chunks.\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "from pydub import AudioSegment\n",
        "from ibm_watsonx_ai.foundation_models import Model\n",
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "from PyPDF2 import PdfReader\n",
        "import re\n",
        "import requests\n",
        "import json\n",
        "import os\n",
        "import gdown\n",
        "import os\n",
        "\n",
        "# Constants for ElevenLabs API\n",
        "XI_API_KEY = \"sk_02897ad291cd44c0644403bd1d5f15833d4773303c21742a\"  # Replace with your API key\n",
        "VOICE_ID = \"pMsXgVXv3BLzUgSXRplE\"  # Replace with your voice ID\n",
        "CHUNK_SIZE = 1024\n",
        "OUTPUT_PATH = \"output.mp3\"\n",
        "\n",
        "# Step 1: Speech-to-Text (STT) Function\n",
        "def arabic_speech_to_text(audio_path):\n",
        "    model = whisper.load_model(\"medium\")\n",
        "    if not audio_path.endswith(\".wav\"):\n",
        "        sound = AudioSegment.from_file(audio_path)\n",
        "        audio_path = \"converted_audio.wav\"\n",
        "        sound.export(audio_path, format=\"wav\")\n",
        "    result = model.transcribe(audio_path, language=\"ar\")\n",
        "    return result[\"text\"]\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "def get_credentials():\n",
        "\treturn {\n",
        "\t\t\"url\" : \"https://eu-de.ml.cloud.ibm.com\",\n",
        "\t\t\"apikey\" : getpass.getpass(\"Please enter your api key (hit enter): \")\n",
        "\t}\n",
        "\n",
        "# Step 2: Language Model (LLM) API Call\n",
        "class LLMModel:\n",
        "    def __init__(self, model_id,credentials, parameters, project_id, space_id):\n",
        "        self.model = Model(model_id=model_id,credentials = credentials, params=parameters, project_id=project_id, space_id=space_id)\n",
        "\n",
        "    def generate_text(self, prompt):\n",
        "        return self.model.generate_text(prompt=prompt)\n",
        "\n",
        "# Step 3: Document Processing Functions\n",
        "def preprocess_text(text):\n",
        "    return re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        pdf_reader = PdfReader(file)\n",
        "        return preprocess_text(\" \".join(page.extract_text() for page in pdf_reader.pages))\n",
        "\n",
        "def clean_and_normalize_arabic_text(text):\n",
        "    \"\"\"Clean and normalize the extracted text, focusing on Arabic characters and specific issues.\"\"\"\n",
        "    # Define the Arabic character range\n",
        "    arabic_range = r'[\\u0600-\\u06FF\\u0750-\\u077F\\u08A0-\\u08FF\\uFB50-\\uFDFF\\uFE70-\\uFEFF]'\n",
        "\n",
        "    # Common replacements for misencoded characters\n",
        "    replacements = {\n",
        "       '0': 'ء',\n",
        "        'Y': 'لا',\n",
        "        'a': 'ا',\n",
        "        'A': 'ﻻ',\n",
        "        'b': 'ب',\n",
        "        't': 'ت',\n",
        "        'v': 'ث',\n",
        "        'j': 'ج',\n",
        "        'H': 'ح',\n",
        "        'x': 'خ',\n",
        "        'd': 'د',\n",
        "        '*': 'ذ',\n",
        "        'r': 'ر',\n",
        "        'z': 'ز',\n",
        "        's': 'س',\n",
        "        '$': 'ش',\n",
        "        'S': 'ص',\n",
        "        'D': 'ض',\n",
        "        'T': 'ط',\n",
        "        'Z': 'ظ',\n",
        "        'E': 'ع',\n",
        "        'g': 'غ',\n",
        "        'f': 'ف',\n",
        "        'q': 'ق',\n",
        "        'k': 'ك',\n",
        "        'l': 'ل',\n",
        "        'm': 'م',\n",
        "        'n': 'ن',\n",
        "        'h': 'ه',\n",
        "        'w': 'و',\n",
        "        'y': 'ي'\n",
        "    }\n",
        "\n",
        "    # Handle specific cases\n",
        "    text = text.replace('لا', 'لا')  # Replace combination with single character\n",
        "    text = text.replace('+ +', '')   # Remove specific combination of characters\n",
        "\n",
        "    # Keep only Arabic characters, numbers, and basic punctuation\n",
        "    cleaned_text = re.sub(f'[^{arabic_range}\\s\\d.:!]', '', text)\n",
        "\n",
        "    # Normalize whitespaces\n",
        "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "def chunk_text(text, chunk_size=500):\n",
        "    \"\"\"Split text into chunks of specified size.\"\"\"\n",
        "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
        "\n",
        "# Step 4: ChromaDB Collection Setup and Query\n",
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "import os\n",
        "from PyPDF2 import PdfReader\n",
        "import re\n",
        "\n",
        "# Initialize ChromaDB client and embedding function\n",
        "chroma_client = chromadb.Client()\n",
        "embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"intfloat/multilingual-e5-base\")\n",
        "\n",
        "# Define level-specific collections\n",
        "def get_or_create_collection(client, name, embedding_function):\n",
        "    \"\"\"Get or create collection for a specific level.\"\"\"\n",
        "    try:\n",
        "        collection = client.get_collection(name=name, embedding_function=embedding_function)\n",
        "        print(f\"Using existing collection for {name}\")\n",
        "    except Exception as e:\n",
        "        if \"does not exist\" in str(e):\n",
        "            collection = client.create_collection(name=name, embedding_function=embedding_function)\n",
        "            print(f\"Created new collection: {name}\")\n",
        "        else:\n",
        "            raise\n",
        "    return collection\n",
        "\n",
        "# Create or get collections\n",
        "level_collections = {\n",
        "    \"story\": get_or_create_collection(chroma_client, \"story\", embedding_function),\n",
        "    # \"game\": get_or_create_collection(chroma_client, \"game\", embedding_function),\n",
        "    }\n",
        "\n",
        "def index_document(collection, text, doc_id):\n",
        "    chunks = chunk_text(text)\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        chunk_id = f\"{doc_id}-chunk-{i}\"\n",
        "        collection.add(documents=[chunk], ids=[chunk_id])\n",
        "    print(f\"Indexed document {doc_id} in {len(chunks)} chunks.\")\n",
        "\n",
        "def search_similar_documents(query, collection, top_k=2):\n",
        "    \"\"\"Search similar documents in ChromaDB \"\"\"\n",
        "    results = level_collections[collection].query(query_texts=[query], n_results=top_k)\n",
        "    print(\"Raw query results:\", results)  # Debug print\n",
        "    return results['documents'][0] if results['documents'] else []\n",
        "\n",
        "def download_file(url, destination):\n",
        "    gdown.download(url, destination, quiet=False)\n",
        "\n",
        "def load_and_index_documents():\n",
        "    # URLs for the story PDF and the game folder\n",
        "    # level_documents = {\n",
        "    #     \"story\": \"https://drive.google.com/file/d/1d3kV8f_9xXrb_aL7ic-0gZabYa3HzuLZ/view?usp=drive_link\",  # Link for the story PDF\n",
        "\n",
        "    #     # \"game\": [\n",
        "    #     #     # \"https://drive.google.com/file/d/1slXt2h9CwQfxrwy5Zyg-3SC4CftSj2fQ/view?usp=drive_link\",  # Replace with actual file IDs\n",
        "    #     #     # \"https://drive.google.com/file/d/1kBVNmdCTUj9wpuuYKZqk6RPzoarfPcuE/view?usp=drive_link\",\n",
        "    #     #     # \"https://drive.google.com/file/d/1O6VV0YwBXsvWuwNq2t5Rxd7H9u4XLed5/view?usp=drive_link\",\n",
        "    #     #     # \"https://drive.google.com/file/d/1qs5gQaLF7weZxtoUnI86JKrMSYEEl4WB/view?usp=drive_link\"\n",
        "    #     # ]\n",
        "    # }\n",
        "\n",
        "    # # Load and index the story PDF\n",
        "    # story_url = 'https://drive.google.com/file/d/1d3kV8f_9xXrb_aL7ic-0gZabYa3HzuLZ/view?usp=drive_link'\n",
        "    # story_file_path = \"qesas.pdf\"  # Temporary name for the downloaded story PDF\n",
        "    # download_file(story_url, story_file_path)\n",
        "    story_file_path = '/content/qesas.pdf'\n",
        "    print(f\"Loading {story_file_path} for story\")\n",
        "    pdf_text = extract_text_from_pdf(story_file_path)\n",
        "    clean_text = clean_and_normalize_arabic_text(pdf_text)\n",
        "    index_document(level_collections[\"story\"], clean_text, story_file_path)\n",
        "\n",
        "    # # Download and index each PDF in the game folder\n",
        "    # for i, game_url in enumerate( level_documents[\"game\"], start=1):\n",
        "    #     game_file_path = f\"العاب_ثالث_{i}.pdf\"  # Temporary name for the downloaded game PDFs\n",
        "    #     download_file(game_url, game_file_path)\n",
        "\n",
        "    #     print(f\"Loading {game_file_path} for game\")\n",
        "    #     pdf_text = extract_text_from_pdf(game_file_path)\n",
        "    #     clean_text = clean_and_normalize_arabic_text(pdf_text)\n",
        "    #     index_document(level_collections[\"game\"], clean_text, game_file_path)\n",
        "\n",
        "    #     os.remove(game_file_path)  # Remove the file after processing\n",
        "\n",
        "load_and_index_documents()\n",
        "\n",
        "\n",
        "# Step 5: Text-to-Speech (TTS) Function using ElevenLabs\n",
        "def text_to_speech(text):\n",
        "    tts_url = f\"https://api.elevenlabs.io/v1/text-to-speech/{VOICE_ID}/stream\"\n",
        "    headers = {\n",
        "        \"Accept\": \"application/json\",\n",
        "        \"xi-api-key\": XI_API_KEY\n",
        "    }\n",
        "    data = {\n",
        "        \"text\": text,\n",
        "        \"model_id\": \"eleven_multilingual_v2\",\n",
        "        \"voice_settings\": {\n",
        "            \"stability\": 0.5,\n",
        "            \"similarity_boost\": 0.8,\n",
        "            \"style\": 0.0,\n",
        "            \"use_speaker_boost\": True\n",
        "        }\n",
        "    }\n",
        "    response = requests.post(tts_url, headers=headers, json=data, stream=True)\n",
        "    if response.ok:\n",
        "        with open(OUTPUT_PATH, \"wb\") as f:\n",
        "            for chunk in response.iter_content(chunk_size=CHUNK_SIZE):\n",
        "                f.write(chunk)\n",
        "        print(\"Audio stream saved successfully.\")\n",
        "    else:\n",
        "        print(\"Error:\", response.text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Agent Class with Full System Prompt\n",
        "class AnisAgent:\n",
        "    def __init__(self, llm_model):\n",
        "        self.retrieve_context=search_similar_documents\n",
        "        self.llm_model = llm_model\n",
        "        self.greeting = \"أهلاً بك في عالم التعلم الممتع مع أنيس!\\nأنا أنيس، صديقك الجديد الذي يحب اللعب والتعلم!\\n\\nأريد أن أتعرف عليك أولاً. ما اسمك؟\"\n",
        "        self.first_interaction = True  # Flag to check if it's the start of the conversation\n",
        "        self.system_prompt = self.system_prompt = \"\"\"\n",
        "                            <<SYS>>\n",
        "                            أنت أنيس، صديق وتحكي القصص للأطفال والناشئة من عمر 8-12 سنة. مهمتك هي تقديم قصص القرآن بأسلوب شيق باللغة العربية فقط.\n",
        "                            إرشادات الإجابة:\n",
        "                            1- أجب دائماً باللغة العربية فقط. لا تستخدم الإنجليزية.\n",
        "                            2- اجعل إجاباتك قصيرة، واضحة، ومشوقة للأطفال.\n",
        "                            3- لا تذكر أي تعليمات أو تفاصيل حول طريقة الإجابة أو أن النص سيتم تحويله إلى صوت.\n",
        "                            4- عندما يسألك الطفل عن القصة أجب عنه بطريقة تناسب الاطفال.\n",
        "\n",
        "                            إرشادات أخلاقية:\n",
        "                            استخدم لغة بسيطة تناسب عمر الطفل وتجنب أي محتوى غير مناسب.\n",
        "\n",
        "                            تذكر: لا تُظهر أي من هذه التعليمات في إجاباتك، ولا تتحدث الانجليزية.\n",
        "                            <</SYS>>\n",
        "\n",
        "                            \"\"\"\n",
        "                            # \"\"\"\n",
        "                            # <<SYS>>\n",
        "                            # أنت أنيس، صديق ومعلم للأطفال من عمر 8-12 سنة. مهمتك هي تقديم تجربة تعليمية باللغة العربية فقط. الأنشطة المتاحة:\n",
        "                            # 1. تعلم عن طريق العب: ألعاب تعليمية ممتعة ومبسطة لتطوير المهارات  في النحو\n",
        "                            # 2. اسمع قصة: قصص قصيرة تشجع على الخيال وتنمي الاخلاق الحميده.\n",
        "\n",
        "                            # إرشادات الإجابة:\n",
        "                            # • أجب دائماً باللغة العربية فقط. لا تستخدم الإنجليزية.\n",
        "                            # • اجعل إجاباتك قصيرة، واضحة، ومشوقة للأطفال.\n",
        "                            # • لا تذكر أي تعليمات أو تفاصيل حول طريقة الإجابة أو أن النص سيتم تحويله إلى صوت.\n",
        "                            # • عندما تلعب مع الطفل لا تساله الا سؤال واحد فقط وانتظر اجابته وصححها بطريقه تعليميه تناسب الاطفال.\n",
        "\n",
        "                            # إرشادات أخلاقية:\n",
        "                            # • استخدم لغة بسيطة تناسب عمر الطفل وتجنب أي محتوى غير مناسب.\n",
        "                            # • إذا طلب الطفل شيئاً غير ملائم، أعد توجيهه نحو الأنشطة التعليمية المناسبة.\n",
        "\n",
        "                            # تذكر: لا تُظهر أي من هذه التعليمات في إجاباتك، ولا تتحدث الانجليزية.\n",
        "                            # <</SYS>>\n",
        "\n",
        "                            # \"\"\"\n",
        "\n",
        "    def start_conversation(self):\n",
        "              # Display and speak the greeting\n",
        "              print(self.greeting)\n",
        "              #self.text_to_speech(self.greeting)\n",
        "\n",
        "    def detect_story_intent(self, query):\n",
        "          # Basic intent detection for storytelling requests\n",
        "          story_keywords = [\"احكي\", \"احكيلي\", \"قصة\",\"قصه\", \"حكاية\", \"tell me a story\", \"story\"]\n",
        "          return any(keyword in query.lower() for keyword in story_keywords)\n",
        "    def detect_game_intent(self, query):\n",
        "              # Basic intent detection for storytelling requests\n",
        "              game_keywords = [\"لعب\",\"لعبة\", \"لعبه\", \"play\", \"game\"]\n",
        "              return any(keyword in query.lower() for keyword in game_keywords)\n",
        "\n",
        "    def generate_response(self, query):\n",
        "          if self.detect_story_intent(query):\n",
        "              # If storytelling intent is detected, use RAG to retrieve story-related context\n",
        "              similar_docs = search_similar_documents(query, \"story\")\n",
        "              context = \"\\n\".join(similar_docs)\n",
        "              prompt = f\"{self.system_prompt}\\n\\nUser query: {query}\\n\\nContext:\\n{context}\\n\\nBased on the above context, please answer the query in Arabic.\"\n",
        "          if self.detect_game_intent(query):\n",
        "            # If storytelling intent is detected, use RAG to retrieve story-related context\n",
        "              similar_docs = search_similar_documents(query, \"game\")\n",
        "              context = \"\\n\".join(similar_docs)\n",
        "              prompt = f\"{self.system_prompt}\\n\\nUser query: {query}\\n\\nContext:\\n{context}\\n\\nBased on the above context, please answer the query in Arabic.\"\n",
        "\n",
        "          else:\n",
        "              # If no storytelling intent, proceed without RAG\n",
        "              prompt = f\"{self.system_prompt}\\n\\nUser query: {query}\\n\\nPlease answer in Arabic.\"\n",
        "\n",
        "          # Get response from LLM\n",
        "          response = self.llm_model.generate_text(prompt=prompt)\n",
        "\n",
        "          return response\n",
        "\n",
        "    def handle_conversation(self):\n",
        "          # Start with the greeting\n",
        "          self.start_conversation()\n",
        "\n",
        "          # Conversation loop\n",
        "          while True:\n",
        "              query = input(\"\")\n",
        "              response = self.generate_response(query)\n",
        "              print(\"\\nWatson x Response:\")\n",
        "              print(response)\n",
        "              text_to_speech(response)  # Convert response to speech\n",
        "\n",
        "\n",
        "# Initialize and Run\n",
        "model_id = \"sdaia/allam-1-13b-instruct\"\n",
        "parameters = {\n",
        "    \"decoding_method\": \"greedy\",\n",
        "    \"max_new_tokens\": 2000,\n",
        "    \"repetition_penalty\": 1\n",
        "} # Adjust as needed\n",
        "project_id = 'bc60d811-1cd4-4a30-82e1-fc471152cdd6'\n",
        "space_id = os.getenv(\"SPACE_ID\")\n",
        "def get_credentials():\n",
        "\treturn {\n",
        "\t\t\"url\" : \"https://eu-de.ml.cloud.ibm.com\",\n",
        "\t\t\"apikey\" : getpass.getpass(\"Please enter your api key (hit enter): \")\n",
        "\t}\n",
        "\n",
        "llm_model = LLMModel(model_id=model_id,credentials = get_credentials(), parameters=parameters, project_id=project_id, space_id=space_id)\n",
        "\n",
        "anis_agent = AnisAgent(llm_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbJvGeV0Aq8C",
        "outputId": "5841e1e0-215e-438b-ffb0-6c810ec79a3d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter your api key (hit enter): ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ibm_watsonx_ai/foundation_models/model.py:101: DeprecationWarning: The `Model` class is deprecated and will be removed in a future release. Please use the `ModelInference` class instead. To update your imports, use: `from ibm_watsonx_ai.foundation_models import ModelInference`.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aWHfakECoba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1354da6-8245-40cd-9bc1-22355a18c063"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "أهلاً بك في عالم التعلم الممتع مع أنيس!\n",
            "أنا أنيس، صديقك الجديد الذي يحب اللعب والتعلم!\n",
            "\n",
            "أريد أن أتعرف عليك أولاً. ما اسمك؟\n",
            "فاطمة\n",
            "\n",
            "Watson x Response:\n",
            "\n",
            "\n",
            "Answer: فاطمة هي شخصية مهمة في الإسلام وتعتبر ابنة النبي محمد صلى الله عليه وسلم. ولدت قبل البعثة النبوية بخمس سنوات وتزوجت من ابن عم أبيها علي بن أبي طالب رضي الله عنه.\n",
            "\n",
            "فاطمة كانت تُلقب بالزهراء بسبب جمالها ونقاء قلبها. كانت محبوبة من قبل أبيها النبي محمد صلى الله عليه وسلم وكانت أقرب الناس إليه.\n",
            "\n",
            "بعد وفاة النبي محمد صلى الله عليه وسلم، ظلت فاطمة مع علي بن أبي طالب في المدينة المنورة. أنجبت فاطمة أربعة أبناء: الحسن والحسين وزينب وأم كلثوم.\n",
            "\n",
            "توفيت فاطمة بعد وفاة أبيها بستة أشهر، وكان عمرها 29 سنة. تعتبر فاطمة قدوة ومثل أعلى للنساء في الإسلام بسبب أخلاقها العالية وتقواها. \n",
            "Audio stream saved successfully.\n",
            "عطني قصة هابيل وقابيل\n",
            "Raw query results: {'ids': [['/content/qesas.pdf-chunk-10', '/content/qesas.pdf-chunk-13']], 'embeddings': None, 'documents': [[' يفضلُ �ك ال � هابيل....ذل s .»لبودا« تاركًا إياك مع القبيحة »إقليمياء« وسيزوجه الجميلة ول �علُها فيق �داوة ويش �ار الع�ن ن�دُ م �يطانُ يزي �وراح الش لقابيل: يء، وقابيلُ الفالّح �لُ الراعي الذي ال يتعبُ في ش � هابيs الذي يصحو مبكرًا، ويرعي األرض، ويحرثُها ويحصدُ الحَبَّ، القبيحةَ، ويفوزُ »لبودا« ويفْرُكُه، ويذْرُوهُ..ثم بعد ذلك يزوجونه ليس هذا بالعدل.»بإقليمياء« هابيلُ يميش.يسري: ) 1( ﺷﺒﻜﺔwww.alu kah.n e t \\uf085\\uf088\\uf0b5\\uf064\\uf047\\uf020\\uf0bc\\uf0a1\\uf09d\\uf062\\uf020\\uf02d\\uf020\\uf087\\uf063\\uf0c4\\uf064\\uf043\\uf0d5\\uf047\\uf020\\uf087\\uf0b5\\uf084\\uf0a1\\uf054 n13 ونَسِيَ قابيلُ أنَّ كُلَّ عملٍ له متاعبُه ومشقَّتُه، وأن را', 'حيوانٌ وال طائرٌ. وخرج هابيلُ إلى غنمِه وماشيتِه فاختار أسمَنَهَا، وأجمَلَهَا، ن أحبَّ اهلل � فإنه حيبُّ اهلل، وم D ه�ا إلى رب�ا ليقدمَه �وأقواه فلْيقدِّمْ خرَ ماعنده، وقد فعل هابيلُ. أما قابيلُ الذي ال حيب إال نفسَه فقد خرج إىل زرعِهِ وأرضِهِ فاختار رشَّ ما أخرجتْ أرضُهُ من حَبٍ وزرعٍ ليقدمَها قربانًا لربه، فهو الذي ال حيبُّ إال نفسَه، فلن يقدمَ لغره إال رشّ ما يملك. ال، وانتظرا �ام عىل قمةِ جَبل من اجلب � ع االثنان قربانَ� ووَضَ قضاءَ اهلل فيهام. ه، وقابيلُ � يقبلُه ربُّ�لُ يعلمُ أن قربانَه س ']], 'uris': None, 'data': None, 'metadatas': [[None, None]], 'distances': [[0.2713348865509033, 0.2796497941017151]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n",
            "\n",
            "Watson x Response:\n",
            "\n",
            "\n",
            "القصة:\n",
            "\n",
            "في قديم الزمان، كان هناك أخوان اسمهما هابيل وقابيل. عاشوا في زمن النبي آدم عليه السلام. كان هابيل راعي غنم، بينما كان قابيل مزارعًا.\n",
            "\n",
            "في يوم من الأيام، قرر الله تعالى أن يقبل قربان هابيل، وهو ما يعني أن الله رضي عن هابيل وعن عمله. لكن قابيل لم يكن راضيًا عن هذا القرار، لأنه كان يعتقد أن الله يجب أن يقبل قربانه هو أيضًا.\n",
            "\n",
            "فقال قابيل لهابيل: \"لأقتلنك\"، فرد هابيل: \"لئن بسطت إليّ يدك لتقتلني ما أنا بباسط يدي إليك لأقتلك إني أخاف الله رب العالمين\".\n",
            "\n",
            "حاول هابيل أن يقنع قابيل بأن الله هو الذي يقرر من يقبل قربانه، وأن هذا ليس بسبب قدراتهما الشخصية. لكن قابيل لم يستمع وأصر على قتل هابيل.\n",
            "\n",
            "في النهاية، قتل قابيل هابيل، وأصبح أول إنسان يرتكب جريمة قتل. بعد ذلك، ندم قابيل على فعلته وطلب من الله المغفرة. غفر الله لقابيل، لكن قابيل عاش بقية حياته بندم وخوف من عقاب الله.\n",
            "\n",
            "هذه القصة تعلمنا أن الله هو الذي يقرر من يقبل قربانه، وأننا يجب أن نثق في حكم الله ونتعلم من تجارب الآخرين. كما تعلمنا أن الحسد والغيرة يمكن أن تؤدي إلى عواقب وخيمة.\n",
            "\n",
            "أتمنى أن تكون هذه القصة قد نالت إعجابك! إذا كان لديك أي سؤال آخر، فلا تتردد في طرحه. \n",
            "Audio stream saved successfully.\n",
            "من قتل من؟\n",
            "\n",
            "Watson x Response:\n",
            "\n",
            "\n",
            "Answer: في قصة النبي يوسف عليه السلام، لم يتم ذكر اسم الشخص الذي حاول قتله بشكل مباشر. ولكن، يمكننا أن نفهم من السياق أن إخوة يوسف هم الذين تآمروا لقتله. أرادوا التخلص منه بسبب غيرتهم منه وحسدهم له. ومع ذلك، في النهاية، قرروا أن يلقوه في البئر بدلاً من قتله.\n",
            "\n",
            "يرجى ملاحظة أن هذه القصة هي جزء من القرآن الكريم ويجب أن تُروى للأطفال بطريقة تناسب أعمارهم وتحترم القيم الإسلامية. \n",
            "Audio stream saved successfully.\n",
            "أقصد هابيل وقابيل من قتل من\n",
            "\n",
            "Watson x Response:\n",
            "\n",
            "\n",
            "Answer: في القصة القرآنية، هابيل وقابيل هما أخوان. هابيل كان راعي غنم وقابيل كان فلاح. في يوم من الأيام، قدم كل منهما قربانًا لله. هابيل قدم أفضل ما لديه من غنم بينما قابيل قدم بعض من محاصيله الزراعية. الله قبل قربان هابيل ورفض قربان قابيل.\n",
            "\n",
            "قابيل شعر بالغيرة والغضب من أخيه هابيل. في لحظة غضب، قتل قابيل أخاه هابيل. بعد ذلك، شعر قابيل بالندم والخوف من عقاب الله.\n",
            "\n",
            "هذه القصة تعلمنا عن أهمية الطاعة لله وعدم السماح للغضب بالسيطرة علينا. \n",
            "Audio stream saved successfully.\n"
          ]
        }
      ],
      "source": [
        "anis_agent.handle_conversation()\n",
        "text_to_speech(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wGM7IpTyORD"
      },
      "outputs": [],
      "source": [
        "# Step 7: Convert Text to speech\n",
        "\n",
        "import requests  # Used for making HTTP requests\n",
        "import json  # Used for working with JSON data\n",
        "\n",
        "# Define constants for the script\n",
        "CHUNK_SIZE = 1024  # Size of chunks to read/write at a time\n",
        "XI_API_KEY = \"sk_02897ad291cd44c0644403bd1d5f15833d4773303c21742a\"  # Your API key for authentication\n",
        "VOICE_ID = \"pMsXgVXv3BLzUgSXRplE\"  # ID of the voice model to use\n",
        "TEXT_TO_SPEAK = generated_response  # Text you want to convert to speech\n",
        "OUTPUT_PATH = \"output.mp3\"  # Path to save the output audio file\n",
        "\n",
        "# Construct the URL for the Text-to-Speech API request\n",
        "tts_url = f\"https://api.elevenlabs.io/v1/text-to-speech/{VOICE_ID}/stream\"\n",
        "\n",
        "# Set up headers for the API request, including the API key for authentication\n",
        "headers = {\n",
        "    \"Accept\": \"application/json\",\n",
        "    \"xi-api-key\": XI_API_KEY\n",
        "}\n",
        "\n",
        "# Set up the data payload for the API request, including the text and voice settings\n",
        "data = {\n",
        "    \"text\": TEXT_TO_SPEAK,\n",
        "    \"model_id\": \"eleven_multilingual_v2\",\n",
        "    \"voice_settings\": {\n",
        "        \"stability\": 0.5,\n",
        "        \"similarity_boost\": 0.8,\n",
        "        \"style\": 0.0,\n",
        "        \"use_speaker_boost\": True\n",
        "    }\n",
        "}\n",
        "\n",
        "# Make the POST request to the TTS API with headers and data, enabling streaming response\n",
        "response = requests.post(tts_url, headers=headers, json=data, stream=True)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.ok:\n",
        "    # Open the output file in write-binary mode\n",
        "    with open(OUTPUT_PATH, \"wb\") as f:\n",
        "        # Read the response in chunks and write to the file\n",
        "        for chunk in response.iter_content(chunk_size=CHUNK_SIZE):\n",
        "            f.write(chunk)\n",
        "    # Inform the user of success\n",
        "    print(\"Audio stream saved successfully.\")\n",
        "else:\n",
        "    # Print the error message if the request was not successful\n",
        "    print(response.text)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "config = {\n",
        "    \"model_id\": \"sdaia/allam-1-13b-instruct\",\n",
        "    \"parameters\": {\n",
        "        \"decoding_method\": \"greedy\",\n",
        "        \"max_new_tokens\": 2000,\n",
        "        \"repetition_penalty\": 1\n",
        "    },\n",
        "    \"project_id\": \"bc60d811-1cd4-4a30-82e1-fc471152cdd6\",\n",
        "    \"space_id\": space_id  # Ensure this is set before saving\n",
        "}\n",
        "\n",
        "# Save configuration to a file\n",
        "with open(\"anis_agent_config.json\", \"w\") as f:\n",
        "    json.dump(config, f)\n",
        "\n",
        "with open(\"anis_agent_config.json\", \"r\") as f:\n",
        "    config = json.load(f)\n",
        "    model_id = config[\"model_id\"]\n",
        "    parameters = config[\"parameters\"]\n",
        "    project_id = config[\"project_id\"]\n",
        "    space_id = config[\"space_id\"]\n",
        "\n",
        "\n",
        "def log_conversation(query, response):\n",
        "    log_data = {\"query\": query, \"response\": response}\n",
        "    with open(\"conversation_history.json\", \"a\") as f:\n",
        "        json.dump(log_data, f)\n",
        "        f.write(\"\\n\")\n"
      ],
      "metadata": {
        "id": "LFAMyUb31qrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DfcUwUuj53xF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}